{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-06T19:30:08.004829Z","iopub.status.busy":"2024-01-06T19:30:08.003882Z","iopub.status.idle":"2024-01-06T19:30:19.890202Z","shell.execute_reply":"2024-01-06T19:30:19.888808Z","shell.execute_reply.started":"2024-01-06T19:30:08.004769Z"},"trusted":true},"outputs":[],"source":["# Data manipulation and utilities\n","import os\n","import numpy as np\n","import glob\n","import pandas as pd\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Preprocessing\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n","from sklearn.preprocessing import StandardScaler\n","\n","# Machine Learning Models\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.svm import SVR\n","from xgboost import XGBRegressor\n","import tensorflow as tf\n","from sklearn.linear_model import ElasticNet\n","\n","# Evaluation Metrics\n","from sklearn.metrics import mean_squared_error, r2_score"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T19:30:19.893676Z","iopub.status.busy":"2024-01-06T19:30:19.892908Z","iopub.status.idle":"2024-01-06T19:30:19.899928Z","shell.execute_reply":"2024-01-06T19:30:19.899022Z","shell.execute_reply.started":"2024-01-06T19:30:19.893632Z"},"trusted":true},"outputs":[],"source":["# Handle warnings\n","import warnings\n","warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T19:30:19.902071Z","iopub.status.busy":"2024-01-06T19:30:19.901229Z"},"trusted":true},"outputs":[],"source":["#read and merged csv file\n","path = \"/kaggle/input/eyet4empathy-eye-movement-and-empathy-dataset/EyeT/EyeT\" \n","all_files = os.listdir(path)\n","\n","df_list = [] \n","for filename in all_files:\n","    if filename.endswith(\".csv\"):\n","        file_path = os.path.join(path, filename)\n","        df = pd.read_csv(file_path, low_memory=False)\n","        df_list.append(df)\n","        \n","cleaned_df = pd.concat(df_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cleaned_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cleaned_df.info"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cleaned_df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#categorial columns\n","data_types = cleaned_df.dtypes\n","categorical_columns = []\n","for column in cleaned_df.columns:\n","    if data_types[column] == 'object':\n","        categorical_columns.append(column)\n","\n","categorical_columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cleaned_df.describe()#descriptive statistics for a Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cleaned_df['Recording date'] = pd.to_datetime(cleaned_df['Recording date'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the directory containing the CSV files\n","csv_directory = '/kaggle/input/eyet4empathy-eye-movement-and-empathy-dataset/EyeT/EyeT'\n","\n","# Create an empty list to hold the resulting dataframes\n","dataframe_list = []\n","\n","# Loop through each file in the directory\n","for filename in os.listdir(csv_directory):\n","    # Check if the file is a CSV file\n","    if filename.endswith('.csv'):\n","        # Read the CSV file\n","        current_dataframe = pd.read_csv(os.path.join(csv_directory, filename))\n","        numeric_columns = current_dataframe.select_dtypes(include=['float64', 'int64'])#Select columns\n","\n","        # Extract the participant name from the first row\n","        participant_name = current_dataframe.loc[0, 'Participant name']\n","\n","        # Drop the 'Participant name' column from the dataframe\n","        current_dataframe = current_dataframe.drop(columns=['Participant name'])\n","\n","        # Add the participant name as a new column\n","        current_dataframe['Participant name'] = participant_name\n","\n","        # Append the resulting dataframe to the list\n","        dataframe_list.append(current_dataframe)\n","\n","# Concatenate all the resulting data into a single dataframe\n","final_df = pd.concat(dataframe_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_df.info()#Details"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_df.isnull().sum()#null value"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Get a list of all the .csv files in the folder\n","filenames = glob.glob(\"/kaggle/input/eyet4empathy-eye-movement-and-empathy-dataset/EyeT/EyeT/*.csv\")\n","Experiment_count = len(filenames)\n","print (\"eye-gaze trajectories : \", Experiment_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["_ = final_df.hist(bins=50, figsize=(20,15))#histogram"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# List of columns to clean\n","columns_to_clean = [\n","    'Pupil diameter right', 'Pupil diameter left', 'Eye position left X (DACSmm)',\n","    'Eye position left Y (DACSmm)', 'Eye position left Z (DACSmm)',\n","    'Eye position right X (DACSmm)', 'Eye position right Y (DACSmm)', 'Eye position right Z (DACSmm)',\n","    'Gaze point left X (DACSmm)', 'Gaze point left Y (DACSmm)', 'Gaze point right X (DACSmm)',\n","    'Gaze point right Y (DACSmm)', 'Gaze point X (MCSnorm)', 'Gaze point Y (MCSnorm)',\n","    'Gaze point left X (MCSnorm)', 'Gaze point left Y (MCSnorm)', 'Gaze point right X (MCSnorm)',\n","    'Gaze point right Y (MCSnorm)', 'Fixation point X (MCSnorm)', 'Fixation point Y (MCSnorm)',\n","    'Gaze direction left X', 'Gaze direction left Y', 'Gaze direction left Z',\n","    'Gaze direction right X', 'Gaze direction right Y', 'Gaze direction right Z'\n","]\n","\n","# Clean columns: replace commas with periods and convert to float\n","for column in columns_to_clean:\n","    final_df[column] = final_df[column].astype(str).str.replace(',', '.').astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["format_string = \"%Y-%m-%d\"\n","final_df['Export date'] = pd.to_datetime(final_df['Export date'], errors='coerce')\n","final_df['Recording date'] = pd.to_datetime(final_df['Export date'], errors='coerce')\n","final_df['Recording date UTC'] = pd.to_datetime(final_df['Recording date UTC'], errors='coerce')\n","final_df['Recording start time'] = pd.to_datetime(final_df['Recording start time'], errors='coerce')\n","final_df['Recording start time UTC'] = pd.to_datetime(final_df['Recording start time UTC'], errors='coerce')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["participant_dict = {}\n","for i in range(1, 61):\n","    participant_dict[f\"Participant{i:04d}\"] = i\n","\n","final_df[\"Participant name\"] = final_df[\"Participant name\"].map(participant_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["main_csv_score = pd.read_csv(\"/kaggle/input/eyet4empathy-eye-movement-and-empathy-dataset/19657323/Questionnaire_datasetIB.csv\", encoding='latin1')\n","main_csv_score = main_csv_score.rename(columns={\"Participant nr\": \"Participant name\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Merge the two datasets based on the Participant name column\n","final_df = pd.merge(final_df, main_csv_score[['Participant name', 'Total Score extended']], on='Participant name', how='left')\n","\n","# Set the timestamp column as the index of the DataFrame\n","final_df.set_index(\"Recording timestamp\", inplace=True)\n","\n","final_df.to_csv(\"eyetzip_data_with_score.csv\", index=False)\n","print(\"CSV file 'eyetzip_data_with_score.csv' saved successfully.\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Combine Raw Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Directory containing the TSV files with raw eye-tracking data\n","directory = \"/kaggle/input/eyet4empathy-eye-movement-and-empathy-dataset/raw_data/raw_data\"\n","\n","# Initialize an empty list to store the loaded dataframes\n","df_list = []\n","\n","# Retrieve a list of all TSV files in the specified directory\n","file_list = glob.glob(directory + '/*.tsv')\n","\n","# Load all files into a list of DataFrames\n","for filepath in file_list:\n","    df = pd.read_csv(filepath, delimiter='\\t', low_memory=False)\n","    df_list.append(df)\n","\n","# Concatenate all DataFrames into a single DataFrame\n","raw_data = pd.concat(df_list, ignore_index=True)\n","raw_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["raw_data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["raw_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert 'Recording date' and 'Export date' columns to datetime format, assuming day comes before month\n","raw_data['Recording date'] = pd.to_datetime(raw_data['Recording date'], dayfirst=True)\n","raw_data['Export date'] = pd.to_datetime(raw_data['Export date'], dayfirst=True)\n","\n","# Define a format string for parsing datetime values\n","format_string = \"%Y-%m-%d\"\n","\n","# Convert 'Export date', 'Recording date', 'Recording date UTC', 'Recording start time', and 'Recording start time UTC' columns\n","# to datetime format using the defined format string. Any errors during conversion are set to NaT (Not a Time).\n","raw_data['Export date'] = pd.to_datetime(raw_data['Export date'], format=format_string, errors='coerce')\n","raw_data['Recording date'] = pd.to_datetime(raw_data['Recording date'], format=format_string, errors='coerce')\n","raw_data['Recording date UTC'] = pd.to_datetime(raw_data['Recording date UTC'], format=format_string, errors='coerce')\n","raw_data['Recording start time'] = pd.to_datetime(raw_data['Recording start time'], format=format_string, errors='coerce')\n","raw_data['Recording start time UTC'] = pd.to_datetime(raw_data['Recording start time UTC'], format=format_string, errors='coerce')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create an empty dictionary to store participant names and corresponding integer values\n","participant_dict = {}\n","\n","# Iterate from 1 to 60 (inclusive)\n","for i in range(1, 61):\n","    # Format participant names with leading zeros (\"Participant0001\" to \"Participant0060\") and map to integers\n","    participant_dict[f\"Participant{i:04d}\"] = i\n","\n","# Map the \"Participant name\" column using the participant_dict\n","raw_data[\"Participant name\"] = raw_data[\"Participant name\"].map(participant_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_csv_score = pd.read_csv(\"/kaggle/input/eyet4empathy-eye-movement-and-empathy-dataset/19657323/Questionnaire_datasetIB.csv\", encoding='latin1')\n","data_csv_score = data_csv_score.rename(columns={\"Participant nr\": \"Participant name\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Read the two datasets\n","raw_data = pd.read_csv(\"raw_data.csv\")\n","data_csv_score = pd.read_csv(\"data_csv_score.csv\")\n","\n","# Define a generator function to merge the two datasets based on the Participant name column\n","def merge_dataframes(raw_data, data_csv_score):\n","    for _, row in raw_data.iterrows():\n","        score = data_csv_score.loc[data_csv_score['Participant name'] == row['Participant name'], 'Total Score extended'].iloc[0]\n","        row['Total Score extended'] = score\n","        yield row\n","\n","# Merge the datasets using the generator function\n","merged_data = pd.DataFrame(merge_dataframes(raw_data, data_csv_score), columns=raw_data.columns)\n","\n","# Set the timestamp column as the index of the DataFrame\n","merged_data.set_index(\"Recording timestamp\", inplace=True)\n","\n","# Save the merged dataset to a CSV file\n","merged_data.to_csv(\"tsv_data_with_score.csv\", index=False)\n","\n","print(\"CSV file 'tsv_data_with_score.csv' saved successfully.\")"]},{"cell_type":"markdown","metadata":{},"source":["# #Load eyetzip_data_with_score.csv with empathy score for data analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df1 = pd.read_csv('/kaggle/working/eyetzip_data_with_score.csv')\n","df1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df1.describe()"]},{"cell_type":"markdown","metadata":{},"source":["#  Visual Analyis for eyetzip_data_with_score.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df1['Recording duration'].hist()\n","plt.title('Recording Duration Distribution')\n","plt.xlabel('Recording Duration')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Scatter plot between `Gaze point X` and `Gaze point Y`\n","df1.plot.scatter(x='Gaze point X', y='Gaze point Y')\n","plt.title('Scatter Plot between Gaze point X and Gaze point Y')\n","plt.show()\n","\n","# Correlation between `Gaze point X` and `Gaze point Y`\n","print(df1[['Gaze point X', 'Gaze point Y']].corr())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a count plot for the 'Eye movement type' column in the DataFrame df1\n","sns.countplot(x='Eye movement type', data=df1)\n","plt.title(\"Distribution of Eye Movement Types\")\n","plt.xlabel(\"Eye Movement Type\")\n","plt.ylabel(\"Count of Observations\")\n","\n","# Display plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Set the figure size for the plot\n","plt.figure(figsize=(14, 7))\n","\n","# Create a boxplot for the distribution of 'Eye movement type index' by 'Project name'\n","sns.boxplot(x=df1['Project name'], y=df1['Eye movement type index'])\n","plt.xlabel('Participant Name')\n","plt.ylabel('Eye Movement Type Index')\n","plt.title('Distribution of Eye Movement Type Index by Participant')\n","plt.xticks(rotation=90)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Select relevant columns (excluding non-numeric columns)\n","numeric_columns = ['Total Score extended', 'Gaze point X', 'Gaze point Y', 'Gaze event duration']\n","subset_df = df1[numeric_columns]\n","\n","# Correlation analysis\n","correlation_matrix = subset_df.corr()\n","\n","# Visualize correlation matrix using a heatmap\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n","plt.title('Correlation Matrix')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Differentiate into two groups based on project names"]},{"cell_type":"markdown","metadata":{},"source":["# Machine Learning Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Select relevant columns for control group\n","control_selected_columns = ['Participant name', 'Recording duration',\n","                             'Pupil diameter left', 'Pupil diameter right',\n","                             'Eye position left X (DACSmm)', 'Eye position left Y (DACSmm)', 'Eye position left Z (DACSmm)',\n","                             'Eye position right X (DACSmm)', 'Eye position right Y (DACSmm)', 'Eye position right Z (DACSmm)',\n","                             'Gaze point left Y', 'Gaze point right X', 'Gaze point right Y',\n","                             'Gaze event duration', 'Fixation point X', 'Fixation point Y', 'Total Score extended', 'Gaze point X', 'Gaze point Y', 'Gaze event duration']\n","\n","# Create a DataFrame with selected columns for control group\n","control_group_selected = control_group_data[control_selected_columns]\n","\n","# Select relevant columns for test group\n","test_selected_columns = ['Participant name', 'Recording duration',\n","                         'Pupil diameter left', 'Pupil diameter right',\n","                         'Eye position left X (DACSmm)', 'Eye position left Y (DACSmm)', 'Eye position left Z (DACSmm)',\n","                         'Eye position right X (DACSmm)', 'Eye position right Y (DACSmm)', 'Eye position right Z (DACSmm)',\n","                         'Gaze point left Y', 'Gaze point right X', 'Gaze point right Y',\n","                         'Gaze event duration', 'Fixation point X', 'Fixation point Y', 'Total Score extended', 'Gaze point X', 'Gaze point Y', 'Gaze event duration']\n","\n","# Create a DataFrame with selected columns for test group\n","test_group_selected = test_group_data[test_selected_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Replace NaN values with 0 in control group dataframe\n","control_group_selected.fillna(0, inplace=True)\n","\n","# Replace NaN values with 0 in test group dataframe\n","test_group_selected.fillna(0, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Calculate Eye Movement Ratios for X, Y, and Z\n","control_group_selected['Eye_Position_Ratio_X'] = control_group_selected['Eye position left X (DACSmm)'] / (control_group_selected['Eye position right X (DACSmm)'] + 1e-6)\n","test_group_selected['Eye_Position_Ratio_X'] = test_group_selected['Eye position left X (DACSmm)'] / (test_group_selected['Eye position right X (DACSmm)'] + 1e-6)\n","\n","control_group_selected['Eye_Position_Ratio_Y'] = control_group_selected['Eye position left Y (DACSmm)'] / (control_group_selected['Eye position right Y (DACSmm)'] + 1e-6)\n","test_group_selected['Eye_Position_Ratio_Y'] = test_group_selected['Eye position left Y (DACSmm)'] / (test_group_selected['Eye position right Y (DACSmm)'] + 1e-6)\n","\n","control_group_selected['Eye_Position_Ratio_Z'] = control_group_selected['Eye position left Z (DACSmm)'] / (control_group_selected['Eye position right Z (DACSmm)'] + 1e-6)\n","test_group_selected['Eye_Position_Ratio_Z'] = test_group_selected['Eye position left Z (DACSmm)'] / (test_group_selected['Eye position right Z (DACSmm)'] + 1e-6)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Calculate Gaze Point Differences for X and Y\n","control_group_selected['Gaze_Point_Diff_X'] = control_group_selected['Gaze point left Y'] - control_group_selected['Gaze point right X']\n","test_group_selected['Gaze_Point_Diff_X'] = test_group_selected['Gaze point left Y'] - test_group_selected['Gaze point right X']\n","\n","control_group_selected['Gaze_Point_Diff_Y'] = control_group_selected['Gaze point left Y'] - control_group_selected['Gaze point right Y']\n","test_group_selected['Gaze_Point_Diff_Y'] = test_group_selected['Gaze point left Y'] - test_group_selected['Gaze point right Y']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Drop columns used in feature engineering\n","columns_to_drop = ['Eye position left X (DACSmm)', 'Eye position right X (DACSmm)',\n","                   'Eye position left Y (DACSmm)', 'Eye position right Y (DACSmm)',\n","                   'Eye position left Z (DACSmm)', 'Eye position right Z (DACSmm)',\n","                   'Gaze point left Y', 'Gaze point right X', 'Gaze point right Y',\n","                   ]\n","\n","control_group_selected.drop(columns=columns_to_drop, inplace=True)\n","test_group_selected.drop(columns=columns_to_drop, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the input features (X) and target variable (y) for control group\n","X_control = control_group_selected.drop(columns=['Total Score extended', 'Participant name', 'Recording duration'])\n","y_control = control_group_selected['Total Score extended']\n","participants_control = control_group_selected['Participant name']\n","\n","# Define the input features (X) and target variable (y) for test group\n","X_test = test_group_selected.drop(columns=['Total Score extended', 'Participant name', 'Recording duration'])\n","y_test = test_group_selected['Total Score extended']\n","participants_test = test_group_selected['Participant name']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv1D, LSTM, GlobalAveragePooling2D, Flatten, Input, concatenate\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras import backend as K"]},{"cell_type":"markdown","metadata":{},"source":["# Model: CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv1D, Flatten\n","\n","# Assuming X_control, y_control, X_test, y_test are your data\n","# You may need to preprocess your data, such as scaling it with StandardScaler\n","scaler = StandardScaler()\n","X_control_scaled = scaler.fit_transform(X_control)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# CNN model\n","cnn_model = Sequential([\n","    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_control.shape[1], 1)),\n","    Flatten(),\n","    Dense(100, activation='relu'),\n","    Dense(50, activation='relu'),\n","    Dense(1)\n","])\n","\n","cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Reshape input for CNN\n","X_control_reshaped = X_control_scaled.reshape((X_control_scaled.shape[0], X_control_scaled.shape[1], 1))\n","X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n","\n","# Training and evaluation for CNN - Control Group\n","print(\"CNN - Control Group:\")\n","cnn_model.fit(X_control_reshaped, y_control, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_control_cnn = cnn_model.predict(X_control_reshaped)\n","print_metrics(\"CNN\", y_control, predictions_control_cnn)\n","\n","# Training and evaluation for CNN - Test Group\n","print(\"CNN - Test Group:\")\n","cnn_model.fit(X_test_reshaped, y_test, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_test_cnn = cnn_model.predict(X_test_reshaped)\n","print_metrics(\"CNN\", y_test, predictions_test_cnn)"]},{"cell_type":"markdown","metadata":{},"source":["# Model:RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# RNN model\n","rnn_model = Sequential([\n","    LSTM(50, activation='relu', input_shape=(X_control.shape[1], 1)),\n","    Dense(100, activation='relu'),\n","    Dense(50, activation='relu'),\n","    Dense(1)\n","])\n","\n","rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Training and evaluation for RNN - Control Group\n","print(\"RNN - Control Group:\")\n","rnn_model.fit(X_control_reshaped, y_control, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_control_rnn = rnn_model.predict(X_control_reshaped)\n","print_metrics(\"RNN\", y_control, predictions_control_rnn)\n","\n","# Training and evaluation for RNN - Test Group\n","print(\"RNN - Test Group:\")\n","rnn_model.fit(X_test_reshaped, y_test, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_test_rnn = rnn_model.predict(X_test_reshaped)\n","print_metrics(\"RNN\", y_test, predictions_test_rnn)"]},{"cell_type":"markdown","metadata":{},"source":["# Model: CapsNet Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from keras import layers\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Custom Capsule Layer\n","class CapsuleLayer(keras.layers.Layer):\n","    def __init__(self, num_capsule, dim_capsule, routings=3, input_shape=None, share_weights=True):\n","        super(CapsuleLayer, self).__init__()\n","        self.num_capsule = num_capsule\n","        self.dim_capsule = dim_capsule\n","        self.routings = routings\n","        self.input_spec = [keras.layers.InputSpec(shape=input_shape)]\n","        self.share_weights = share_weights\n","\n","    def build(self, input_shape):\n","        if self.share_weights:\n","            if self.input_spec[0].shape[1]:\n","                self.kernel = self.add_weight(name='capsule_kernel',\n","                                              shape=(1, input_shape[0][-1], self.num_capsule * self.dim_capsule),\n","                                              initializer='glorot_uniform',\n","                                              trainable=True)\n","            else:\n","                self.kernel = self.add_weight(name='capsule_kernel',\n","                                              shape=(input_shape[0][-1], self.num_capsule * self.dim_capsule),\n","                                              initializer='glorot_uniform',\n","                                              trainable=True)\n","\n","    def call(self, inputs, training=None):\n","        # Expand the input dimensions to 1 for correct reshaping\n","        inputs = tf.expand_dims(inputs, axis=-1)\n","        if self.share_weights:\n","            capsule_kernel = tf.tile(self.kernel, [tf.shape(inputs)[0], 1, 1])\n","        else:\n","            capsule_kernel = tf.tile(self.kernel, [1, 1, tf.shape(inputs)[1], 1])\n","\n","        capsule_kernel = tf.expand_dims(capsule_kernel, -1)\n","        capsule_output = tf.keras.layers.Conv2D(filters=self.num_capsule * self.dim_capsule, kernel_size=1, strides=1, padding='VALID')(inputs)\n","        capsule_output = tf.expand_dims(capsule_output, -1)\n","\n","        vote_output = tf.matmul(capsule_output, capsule_kernel, transpose_b=True)\n","        vote_output = tf.squeeze(vote_output, axis=-1)\n","        for _ in range(self.routings):\n","            routing_weight = tf.nn.softmax(vote_output, axis=2)\n","            vote_output = tf.zeros_like(vote_output)\n","            for i in range(self.num_capsule):\n","                output_for_i = tf.matmul(routing_weight[:, :, i : i + 1], capsule_output, transpose_a=True)\n","                output_for_i = tf.reshape(output_for_i, [-1, self.dim_capsule])\n","                vote_output += output_for_i\n","            vote_output = tf.expand_dims(vote_output, -1)\n","        return vote_output\n","\n","    def compute_output_shape(self, input_shape):\n","        return (None, self.num_capsule, self.dim_capsule, 1)\n","\n","# Assuming X_control, y_control, X_test, y_test are your data\n","# You may need to preprocess your data, such as scaling it with StandardScaler\n","scaler = StandardScaler()\n","X_control_scaled = scaler.fit_transform(X_control)\n","X_test_scaled = scaler.transform(X_test)\n","\n","capsnet_model = Sequential([\n","    CapsuleLayer(num_capsule=10, dim_capsule=16, routings=3, input_shape=(X_control.shape[1],)),\n","    Dense(100, activation='relu'),\n","    Dense(50, activation='relu'),\n","    Dense(1)\n","])\n","\n","capsnet_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Training and evaluation for CapsNet - Control Group\n","print(\"CapsNet - Control Group:\")\n","capsnet_model.fit(X_control_scaled, y_control, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_control_capsnet = capsnet_model.predict(X_control_scaled)\n","print_metrics(\"CapsNet\", y_control, predictions_control_capsnet)\n","\n","# Training and evaluation for CapsNet - Test Group\n","print(\"CapsNet - Test Group:\")\n","capsnet_model.fit(X_test_scaled, y_test, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_test_capsnet = capsnet_model.predict(X_test_scaled)\n","print_metrics(\"CapsNet\", y_test, predictions_test_capsnet)"]},{"cell_type":"markdown","metadata":{},"source":["# Model: GoogLeNet Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_googlenet_model(input_shape):\n","    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n","    base_model.trainable = False\n","\n","    model = Sequential([\n","        base_model,\n","        GlobalAveragePooling2D(),\n","        Dense(100, activation='relu'),\n","        Dense(50, activation='relu'),\n","        Dense(1)\n","    ])\n","\n","    return model\n","\n","input_shape_googlenet = (X_control_scaled.shape[1],)\n","googlenet_model = create_googlenet_model(input_shape_googlenet)\n","\n","googlenet_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Training and evaluation for GoogLeNet - Control Group\n","print(\"GoogLeNet - Control Group:\")\n","googlenet_model.fit(X_control_scaled, y_control, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_control_googlenet = googlenet_model.predict(X_control_scaled)\n","print_metrics(\"GoogLeNet\", y_control, predictions_control_googlenet)\n","\n","# Training and evaluation for GoogLeNet - Test Group\n","print(\"GoogLeNet - Test Group:\")\n","googlenet_model.fit(X_test_scaled, y_test, epochs=10, batch_size=32, validation_split=0.2)\n","predictions_test_googlenet = googlenet_model.predict(X_test_scaled)\n","print_metrics(\"GoogLeNet\", y_test, predictions_test_googlenet)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4193435,"sourceId":7240695,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
